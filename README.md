
# Deep-Learning-Framework
A deep learning framework, made from scratch in python.

## Introduction

My goal with this project is to combine my knowledge of calculus/matrices with my knowledge of the feedforward function in neural networks, to learn the concept of backpropagation. The final goal is to be able to implement it in this project.

I will also make the model scalable to any size, so that this program could potentially be used as an API for a real project.

Finally, in this project, I am going to challenge myself to program the entire thing without reading the example code in Michael Nielsen's book. Instead, I'm going to study the algorithms conceptually, and try to implement them 'freestyle.' This is because I want to make sure I am properly learning the concepts, rather than mindlessly plagiarising.

## Requirements
 * Numpy (for matrix operations)  
```python -m pip install numpy```

## Installing and Running
*(not yet implemented)*

## Features
 * *(not yet implemented)* Neural network model with scalable size, and feedforward capability using weight matrices
 * *(not yet implemented)* Backpropagation step function, that can be iterated
 * *(not yet implemented)* I might use the API to create a GUI web app, where the user can experiment with different sizes and datasets
 * *(not yet implemented)* More sophisticated types of neural networks, like CNNs or RNNs, rather than the basic feedforward net

## Sources
My main research for this project.
 * *Neural Networks and Deep Learning* ebook by Michael Nielsen:  
http://neuralnetworksanddeeplearning.com/
 * *Neural Networks* web series by Grant Sanderson:  
https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi
 * *A Derivation of Backpropagation in Matrix Form* article by Sudeep Raja:  
https://sudeepraja.github.io/Neural/
 * *Matrix Based Back-propagation* article by Hind Sellouk:  
https://medium.com/@hindsellouk13/matrix-based-back-propagation-fe143ce2b2df
